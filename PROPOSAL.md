# ds-sandbox å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆ

> **ç‰ˆæœ¬**: v1.0
> **æ—¥æœŸ**: 2026-02-12
> **çŠ¶æ€**: è®¾è®¡æ–¹æ¡ˆï¼ˆæœ€ç»ˆç‰ˆï¼‰

---

## ğŸ“‹ ç›®å½•

- [ä¸€ã€æ–¹æ¡ˆæ‘˜è¦](#ä¸€æ–¹æ¡ˆæ‘˜è¦)
- [äºŒã€æ ¸å¿ƒåŸåˆ™](#äºŒæ ¸å¿ƒåŸåˆ™)
- [ä¸‰ã€é¡¹ç›®ç»“æ„](#ä¸‰é¡¹ç›®ç»“æ„)
- [å››ã€æ ¸å¿ƒæ¨¡å—](#å››æ ¸å¿ƒæ¨¡å—)
- [äº”ã€å…¬å…±æ¥å£](#äº”å…¬å…±æ¥å£)
- [å…­ã€å®‰å…¨è®¾è®¡](#å…­å®‰å…¨è®¾è®¡)
- [ä¸ƒã€APIè®¾è®¡](#ä¸ƒapiè®¾è®¡)
- [å…«ã€SDKè®¾è®¡](#å…«sdkè®¾è®¡)
- [ä¹ã€æ•°æ®ç®¡ç†](#ä¹æ•°æ®ç®¡ç†)
- [åã€æµ‹è¯•ç­–ç•¥](#åæµ‹è¯•ç­–ç•¥)
- [åä¸€ã€é‡Œç¨‹ç¢‘](#åä¸€é‡Œç¨‹ç¢‘)
- [åäºŒã€æŠ€æœ¯é€‰å‹](#åäºŒæŠ€æœ¯é€‰å‹)

---

## ä¸€ã€æ–¹æ¡ˆæ‘˜è¦

### 1.1 èƒŒæ™¯ä¸é—®é¢˜

**å½“å‰ç°çŠ¶**ï¼š
- âŒ ç¼ºä¹å¼€æºçš„ç”Ÿäº§çº§æ•°æ®ç§‘å­¦æ²™ç®±
- âŒ ç°æœ‰æ–¹æ¡ˆè¦ä¹ˆå¤ªä¸“ç”¨ï¼ˆe2b.devï¼‰ï¼Œè¦ä¹ˆå¤ªé€šç”¨ï¼ˆæ— æ•°æ®ç®¡ç†ï¼‰
- âŒ AI agentä»£ç æ‰§è¡Œç¼ºä¹ç»Ÿä¸€çš„workspace-firstæ•°æ®è®¿é—®æ–¹æ¡ˆ

**æ ¸å¿ƒéœ€æ±‚**ï¼š
```
è¾“å…¥ï¼šcode + workspace + datasets
è¾“å‡ºï¼šExecutionResult + artifacts
éš”ç¦»ï¼šå¯é…ç½®ï¼ˆDocker/Firecracker/Kataï¼‰
æ¥å£ï¼šREST / Python SDK / MCP
```

### 1.2 ç›®æ ‡å®šä½

**é¡¹ç›®å®šä½**ï¼š
- ğŸ“¦ **å®Œå…¨ç‹¬ç«‹**çš„PythonåŒ…ï¼ˆå‘½å `ds-sandbox`ï¼‰
- ğŸ¯ **é€šç”¨ç›®çš„** - ä»»ä½•AI/MLé¡¹ç›®å¯ä½¿ç”¨
- ğŸ”§ **å¯æ’æ‹”æ¶æ„** - æ”¯æŒå¤šç§éš”ç¦»åç«¯
- ğŸ“ **Workspaceä¼˜å…ˆ** - æ•°æ®åœ¨å·¥ä½œç›®å½•ä¸­ï¼Œç›¸å¯¹è·¯å¾„è®¿é—®
- ğŸŒ **å¤šæ¥å£æ”¯æŒ** - RESTã€Python SDKã€MCPæœåŠ¡å™¨

**ä¸åšä»€ä¹ˆ**ï¼ˆæ˜ç¡®è¾¹ç•Œï¼‰ï¼š
- âŒ **ä¸å®ç°** AutoMLè®­ç»ƒç¼–æ’
- âŒ **ä¸å®ç°** ç‰¹å®šAgentå·¥ä½œæµï¼ˆAIDEã€AutoMindç­‰ï¼‰
- âŒ **ä¸ç»‘å®š** ä»»ä½•ä¸Šå±‚ä¸šåŠ¡æ¡†æ¶
- âœ… **åªæä¾›** åº•å±‚ä»£ç æ‰§è¡Œèƒ½åŠ›

### 1.3 æ ¸å¿ƒä»·å€¼

1. **ç»Ÿä¸€æŠ½è±¡å±‚** - ä¸åŒåç«¯ç”¨ç»Ÿä¸€æ¥å£
2. **WorkspaceåŸç”Ÿ** - æ•°æ®åœ¨workspaceç›¸å¯¹è·¯å¾„è®¿é—®ï¼Œç¬¦åˆDSä¹ æƒ¯
3. **ç­–ç•¥é©±åŠ¨** - æ ¹æ®å®‰å…¨ç­–ç•¥è‡ªåŠ¨é€‰æ‹©éš”ç¦»çº§åˆ«
4. **ç”Ÿäº§å°±ç»ª** - å®¡è®¡ã€ç›‘æ§ã€é™æµã€æ•…éšœæ³¨å…¥
5. **æ˜“äºé›†æˆ** - ä¸‰ç§æ¥å£é€‚é…ä¸åŒä½¿ç”¨åœºæ™¯

---

## äºŒã€æ ¸å¿ƒåŸåˆ™

### 2.1 Workspace-FirståŸåˆ™

**å®šä¹‰**ï¼š
```python
# ç”¨æˆ·ä»£ç è§†è§’
import pandas as pd
df = pd.read_csv('data/train.csv')      # âœ… ç›¸å¯¹è·¯å¾„ï¼Œç›´è§‚
model.save('models/rf.pkl')              # âœ… ç›¸å¯¹è·¯å¾„ï¼Œå¯é¢„æµ‹

# âŒ ä¸æ¨è
df = pd.read_csv('/data/bike/train.csv')  # ç¡¬ç¼–ç ï¼Œéš¾ç»´æŠ¤
df = pd.read_csv('/mnt/datasets/bike/train.csv')  # ç»å¯¹è·¯å¾„ï¼Œä¸é€šç”¨
```

**æ¶æ„ä¿è¯**ï¼š
```
Workspaceç»“æ„ï¼š
/opt/workspaces/{workspace_id}/
  â”œâ”€â”€ data/          # æ•°æ®é›†ï¼ˆåªè¯»æˆ–è¯»å†™ï¼‰
  â”œâ”€â”€ models/        # æ¨¡å‹æŒä¹…åŒ–
  â”œâ”€â”€ outputs/      # è¾“å‡ºæ–‡ä»¶
  â””â”€â”€ .workspace/   # å…ƒæ•°æ®

SandboxæŒ‚è½½ï¼š
host: /opt/workspaces/user-123  â†’  guest: /workspace

å·¥ä½œç›®å½•å›ºå®šï¼š/workspace
```

### 2.2 ç­–ç•¥é©±åŠ¨å®‰å…¨

**è‡ªåŠ¨éš”ç¦»çº§åˆ«é€‰æ‹©**ï¼š
```python
class SecurityContext(BaseModel):
    network_disabled: bool = True
    enable_gpu: bool = False

    @computed_field
    def recommended_isolation(self) -> str:
        if self.enable_gpu:
            return "secure"      # GPUéœ€è¦VMéš”ç¦»
        elif not self.network_disabled:
            return "secure"      # ç½‘ç»œè®¿é—®éœ€è¦VM
        return "fast"           # é»˜è®¤ç”¨Docker
```

### 2.3 å¯æ’æ‹”åç«¯åŸåˆ™

**åç«¯å¥‘çº¦**ï¼š
```python
class SandboxBackend(ABC):
    @abstractmethod
    async def execute(
        self,
        request: ExecutionRequest,
        workspace: Workspace
    ) -> ExecutionResult:
        """æ‰§è¡Œä»£ç å¹¶è¿”å›ç»“æœ"""

    @abstractmethod
    async def health_check(self) -> BackendStatus:
        """åç«¯å¥åº·æ£€æŸ¥"""
```

**æ”¯æŒçš„åç«¯**ï¼š
1. **Docker** (~100mså¯åŠ¨) - é»˜è®¤ï¼Œå¿«é€Ÿè¿­ä»£
2. **Firecracker** (~200mså¯åŠ¨) - ç”Ÿäº§ç¯å¢ƒï¼Œå¼ºéš”ç¦»
3. **Kata Containers** (~1så¯åŠ¨) - K8såŸç”Ÿï¼Œå¯é€‰

---

## ä¸‰ã€é¡¹ç›®ç»“æ„

```
ds-sandbox/                                      # é¡¹ç›®æ ¹ç›®å½•
â”œâ”€â”€ pyproject.toml                               # æ‰“åŒ…é…ç½®
â”œâ”€â”€ README.md                                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ LICENSE                                      # Apache-2.0
â”œâ”€â”€ PROPOSAL.md                                  # æœ¬æ–‡æ¡£
â”‚
â”œâ”€â”€ src/ds_sandbox/                            # æºä»£ç åŒ…
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚                                        # å…¬å¼€API: SandboxManager, SandboxSDK
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                              # é…ç½®æ¨¡å‹
â”‚   â”œâ”€â”€ types.py                                # å…¬å…±ç±»å‹å®šä¹‰
â”‚   â”œâ”€â”€ errors.py                               # å¼‚å¸¸å®šä¹‰
â”‚   â”‚
â”‚   â”œâ”€â”€ manager.py                              # ğŸ”‘ æ ¸å¿ƒç®¡ç†å™¨
â”‚   â”‚   # - åç«¯è·¯ç”±
â”‚   â”‚   # - ç­–ç•¥å†³ç­–
â”‚   â”‚   # - æ‰§è¡Œç¼–æ’
â”‚   â”‚
â”‚   â”œâ”€â”€ backends/                               # éš”ç¦»åç«¯
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                              # æŠ½è±¡æ¥å£
â”‚   â”‚   â”œâ”€â”€ docker.py                              # Dockerå®ç°
â”‚   â”‚   â”œâ”€â”€ firecracker.py                         # Firecrackerå®ç°ï¼ˆPhase 2ï¼‰
â”‚   â”‚   â”œâ”€â”€ kata.py                               # Kataå®ç°ï¼ˆPhase 2ï¼‰
â”‚   â”‚   â””â”€â”€ router.py                           # åç«¯è·¯ç”±å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ workspace/                              # Workspaceç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ manager.py                           # Workspaceç”Ÿå‘½å‘¨æœŸ
â”‚   â”‚   â””â”€â”€ service.py                           # WorkspaceæœåŠ¡
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                                   # æ•°æ®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ registry.py                           # æ•°æ®é›†æ³¨å†Œè¡¨
â”‚   â”‚   â”œâ”€â”€ mounter.py                            # æŒ‚è½½ç®¡ç†
â”‚   â”‚   â””â”€â”€ catalog.py                            # æ•°æ®é›†ç›®å½•
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                                # å­˜å‚¨æŠ½è±¡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ volumes.py                            # å·ç®¡ç†
â”‚   â”‚   â””â”€â”€ snapshots.py                          # å¿«ç…§åŠŸèƒ½ï¼ˆPhase 4ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ security/                               # å®‰å…¨å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ policies.py                            # ç½‘ç»œç­–ç•¥
â”‚   â”‚   â”œâ”€â”€ scanner.py                            # ä»£ç æ‰«æ
â”‚   â”‚   â””â”€â”€ audit.py                             # å®¡è®¡æ—¥å¿—
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/                              # ç›‘æ§æŒ‡æ ‡
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ metrics.py                            # PrometheusæŒ‡æ ‡
â”‚   â”‚
â”‚   â””â”€â”€ api/                                   # æ¥å£å±‚
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ rest.py                               # FastAPIæœåŠ¡å™¨
â”‚       â”œâ”€â”€ sdk.py                                # Python SDK
â”‚       â””â”€â”€ mcp.py                                # MCPæœåŠ¡å™¨
â”‚
â”œâ”€â”€ tests/                                     # æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                            # pytesté…ç½®
â”‚   â”œâ”€â”€ test_manager.py                         # æ ¸å¿ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_backends/                        # åç«¯æµ‹è¯•
â”‚   â”‚   â”œâ”€â”€ test_docker.py
â”‚   â”‚   â””â”€â”€ test_firecracker.py
â”‚   â”œâ”€â”€ test_workspace/                      # Workspaceæµ‹è¯•
â”‚   â”œâ”€â”€ test_data/                           # æ•°æ®ç®¡ç†æµ‹è¯•
â”‚   â””â”€â”€ test_api/                            # APIæµ‹è¯•
â”‚
â”œâ”€â”€ docs/                                      # æ–‡æ¡£
â”‚   â”œâ”€â”€ architecture.md                        # æ¶æ„è¯´æ˜
â”‚   â”œâ”€â”€ security.md                          # å®‰å…¨ä¿è¯
â”‚   â”œâ”€â”€ api.md                              # APIæ–‡æ¡£
â”‚   â””â”€â”€ performance.md                      # æ€§èƒ½åŸºå‡†
â”‚
â”œâ”€â”€ examples/                                   # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ basic_execution.py                 # åŸºç¡€æ‰§è¡Œ
â”‚   â”œâ”€â”€ model_training.py                   # æ¨¡å‹è®­ç»ƒ
â”‚   â””â”€â”€ multi_workspace.py                # å¤šworkspaceç®¡ç†
â”‚
â”œâ”€â”€ scripts/                                   # å®ç”¨è„šæœ¬
â”‚   â”œâ”€â”€ setup_dev_env.sh                  # å¼€å‘ç¯å¢ƒè®¾ç½®
â”‚   â””â”€â”€ benchmark.py                         # æ€§èƒ½æµ‹è¯•
â”‚
â””â”€â”€ deployment/                                # éƒ¨ç½²é…ç½®
    â”œâ”€â”€ docker/
    â”‚   â””â”€â”€ docker-compose.yml             # æœ¬åœ°å¼€å‘
    â”œâ”€â”€ kubernetes/
    â”‚   â”œâ”€â”€ crds/                          # Custom Resource Definitions
    â”‚   â””â”€â”€ helm/                          # Helm Charts
    â””â”€â”€ cloud/
        â””â”€â”€ aws/                         # AWSéƒ¨ç½²
            â””â”€â”€ ecs.tf                  # Terraformé…ç½®
```

---

## å››ã€æ ¸å¿ƒæ¨¡å—

### 4.1 SandboxManagerï¼ˆæ ¸å¿ƒç¼–æ’å™¨ï¼‰

**èŒè´£**ï¼š
- åç«¯æ³¨å†Œä¸è·¯ç”±
- è¯·æ±‚éªŒè¯ä¸ç­–ç•¥å†³ç­–
- æ‰§è¡Œç”Ÿå‘½å‘¨æœŸç®¡ç†
- èµ„æºé…é¢ç®¡ç†

**æ¥å£è®¾è®¡**ï¼š
```python
class SandboxManager:
    """æ²™ç®±ç®¡ç†å™¨ - å•ä¸€å…¥å£ç‚¹"""

    def __init__(
        self,
        config: SandboxConfig = SandboxConfig()
    ):
        self.config = config
        self._backends: Dict[str, SandboxBackend] = {}
        self._router = IsolationRouter(config)

    async def execute(
        self,
        code: str,
        workspace_id: str,
        datasets: List[str] = None,
        mode: str = "safe"
        timeout_sec: int = 3600
    ) -> ExecutionResult:
        """
        æ ¸å¿ƒæ‰§è¡Œæ–¹æ³•

        æµç¨‹ï¼š
        1. éªŒè¯workspaceå­˜åœ¨
        2. å‡†å¤‡datasetsåˆ°workspace/data/
        3. æ ¹æ®ç­–ç•¥é€‰æ‹©backend
        4. æŒ‚è½½workspaceåˆ°sandbox
        5. æ‰§è¡Œä»£ç 
        6. æ”¶é›†ç»“æœ
        7. å†™å®¡è®¡æ—¥å¿—
        8. è¿”å›ExecutionResult
        """
```

### 4.2 IsolationRouterï¼ˆç­–ç•¥è·¯ç”±å™¨ï¼‰

**è·¯ç”±å†³ç­–**ï¼š
```python
class IsolationRouter:
    """éš”ç¦»çº§åˆ«è·¯ç”±å™¨"""

    def decide_backend(
        self,
        request: ExecutionRequest,
        code_scan: CodeScanResult
    ) -> str:
        """
        å†³ç­–é€»è¾‘ï¼š

        1. å¦‚æœrequestæ˜ç¡®æŒ‡å®šbackend â†’ ä½¿ç”¨æŒ‡å®šbackend
        2. å¦‚æœcode_scan.high_risk â†’ Firecracker
        3. å¦‚æœæœ‰GPUéœ€æ±‚ â†’ Firecracker
        4. å¦‚æœç½‘ç»œè®¿é—® â†’ Firecracker
        5. é»˜è®¤ â†’ Docker
        """

        risk_score = self._calculate_risk(
            code_scan.risk_score,
            request.security_context
        )

        if risk_score > 0.7:
            return "firecracker"
        elif risk_score > 0.3:
            return "docker"
        else:
            return "docker"
```

### 4.3 WorkspaceManagerï¼ˆå·¥ä½œåŒºç®¡ç†ï¼‰

**èŒè´£**ï¼š
- Workspaceç”Ÿå‘½å‘¨æœŸç®¡ç†
- ç›®å½•ç»“æ„åˆ›å»ºä¸æ¸…ç†
- æ•°æ®é›†å‡†å¤‡ä¸æŒ‚è½½

**æ¥å£**ï¼š
```python
class WorkspaceManager:
    """Workspaceç”Ÿå‘½å‘¨æœŸç®¡ç†"""

    async def create(
        self,
        workspace_id: str,
        setup_dirs: List[str] = ["data", "models", "outputs"]
    ) -> Workspace:
        """
        åˆ›å»ºworkspaceç›®å½•ç»“æ„ï¼š
        /opt/workspaces/{workspace_id}/
          â”œâ”€â”€ data/
          â”œâ”€â”€ models/
          â”œâ”€â”€ outputs/
          â””â”€â”€ .workspace/meta.json
        """

    async def prepare_datasets(
        self,
        workspace_id: str,
        dataset_names: List[str]
    ) -> None:
        """
        ä»ä¸­å¤®æ•°æ®ä»“åº“å¤åˆ¶/é“¾æ¥æ•°æ®é›†åˆ°workspace/data/

        å®ç°ï¼š
        - å•ç§Ÿæˆ·ï¼šcopyï¼ˆéš”ç¦»ï¼‰
        - å¤šç§Ÿæˆ·ï¼šlinkï¼ˆå…±äº«ï¼‰
        """

    def get_mount_config(
        self,
        workspace: Workspace
    ) -> MountConfig:
        """ç”ŸæˆDocker/K8sæŒ‚è½½é…ç½®"""
```

---

## äº”ã€å…¬å…±æ¥å£

### 5.1 Executionç±»å‹ç³»ç»Ÿ

**æ ¸å¿ƒç±»å‹å®šä¹‰**ï¼š
```python
from pydantic import BaseModel, Field
from typing import List, Literal, Optional, Dict, Any

class ExecutionRequest(BaseModel):
    """ä»£ç æ‰§è¡Œè¯·æ±‚"""

    # åŸºç¡€å‚æ•°
    code: str = Field(..., description="Pythonä»£ç ")
    workspace_id: str = Field(..., description="Workspace ID")

    # æ•°æ®å‡†å¤‡
    datasets: List[str] = Field(
        default_factory=list,
        description="æ•°æ®é›†åç§°åˆ—è¡¨ï¼ˆä¼šå‡†å¤‡åˆ°workspace/data/ï¼‰"
    )
    data_mounts: Dict[str, str] = Field(
        default_factory=dict,
        description="è‡ªå®šä¹‰æ•°æ®æŒ‚è½½ï¼ˆè·¯å¾„æ˜ å°„ï¼‰"
    )

    # æ‰§è¡Œæ§åˆ¶
    mode: Literal["safe", "fast", "secure"] = Field(
        default="safe",
        description="æ‰§è¡Œæ¨¡å¼ï¼ˆå½±å“éš”ç¦»çº§åˆ«é€‰æ‹©ï¼‰"
    )
    timeout_sec: int = Field(
        default=3600,
        ge=1,
        le=86400,
        description="è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
    )

    # èµ„æºé™åˆ¶
    memory_mb: int = Field(
        default=4096,
        ge=512,
        le=65536,
        description="å†…å­˜é™åˆ¶ï¼ˆMBï¼‰"
    )
    cpu_cores: float = Field(
        default=2.0,
        ge=0.5,
        le=16.0,
        description="CPUæ ¸å¿ƒæ•°"
    )
    enable_gpu: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨GPU"
    )

    # å®‰å…¨é…ç½®
    network_policy: Literal["disabled", "whitelist", "proxy"] = Field(
        default="disabled",
        description="ç½‘ç»œè®¿é—®ç­–ç•¥"
    )
    network_whitelist: List[str] = Field(
        default_factory=list,
        description="ç½‘ç»œç™½åå•ï¼ˆå½“network_policy=whitelistæ—¶ï¼‰"
    )

    # ç¯å¢ƒå˜é‡
    env_vars: Dict[str, str] = Field(
        default_factory=dict,
        description="æ‰§è¡Œç¯å¢ƒå˜é‡"
    )

class ExecutionResult(BaseModel):
    """æ‰§è¡Œç»“æœ"""

    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    stdout: str = Field(..., description="æ ‡å‡†è¾“å‡º")
    stderr: str = Field(default="", description="æ ‡å‡†é”™è¯¯è¾“å‡º")

    # æ‰§è¡Œè¯¦æƒ…
    exit_code: Optional[int] = Field(None, description="é€€å‡ºç ")
    duration_ms: int = Field(..., description="æ‰§è¡Œè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰")

    # äº§å‡º
    artifacts: List[str] = Field(
        default_factory=list,
        description="ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºworkspaceï¼‰"
    )

    # å…ƒæ•°æ®
    execution_id: str = Field(..., description="æ‰§è¡ŒID")
    workspace_id: str = Field(..., description="Workspace ID")
    backend: str = Field(..., description="ä½¿ç”¨çš„åç«¯")
    isolation_level: str = Field(..., description="å®é™…éš”ç¦»çº§åˆ«")

    # å®¡è®¡ä¿¡æ¯
    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description="é™„åŠ å…ƒæ•°æ®"
    )

class Workspace(BaseModel):
    """Workspaceä¿¡æ¯"""

    workspace_id: str = Field(..., description="Workspaceå”¯ä¸€æ ‡è¯†")
    host_path: str = Field(..., description="å®¿ä¸»æœºè·¯å¾„")
    guest_path: str = Field(default="/workspace", description="æ²™ç®±å†…è·¯å¾„")
    subdirs: List[str] = Field(
        default=["data", "models", "outputs"],
        description="Workspaceå­ç›®å½•"
    )
    status: Literal["creating", "ready", "archived"] = Field(
        default="ready",
        description="WorkspaceçŠ¶æ€"
    )
    created_at: str = Field(..., description="åˆ›å»ºæ—¶é—´ï¼ˆISO 8601ï¼‰")
    last_used_at: Optional[str] = Field(None, description="æœ€åä½¿ç”¨æ—¶é—´")
```

### 5.2 æ•°æ®ç®¡ç†ç±»å‹

```python
class DatasetInfo(BaseModel):
    """æ•°æ®é›†ä¿¡æ¯"""

    name: str = Field(..., description="æ•°æ®é›†åç§°")
    source_path: str = Field(..., description="æ•°æ®é›†æºè·¯å¾„ï¼ˆä¸­å¤®ä»“åº“ï¼‰")
    size_mb: float = Field(..., ge=0, description="æ•°æ®é›†å¤§å°ï¼ˆMBï¼‰")
    format: Literal["csv", "parquet", "json", "excel", "feather"] = Field(
        ...,
        description="æ•°æ®æ ¼å¼"
    )
    description: Optional[str] = Field(None, description="æ•°æ®é›†æè¿°")
    tags: List[str] = Field(
        default_factory=list,
        description="æ ‡ç­¾ï¼ˆç”¨äºåˆ†ç±»å’Œæœç´¢ï¼‰"
    )
    registered_at: str = Field(..., description="æ³¨å†Œæ—¶é—´ï¼ˆISO 8601ï¼‰")

class MountConfig(BaseModel):
    """æŒ‚è½½é…ç½®"""

    workspace_id: str = Field(..., description="Workspace ID")
    workspace_host_path: str = Field(..., description="å®¿ä¸»æœºworkspaceè·¯å¾„")
    workspace_guest_path: str = Field(
        default="/workspace",
        description="æ²™ç®±å†…æŒ‚è½½ç‚¹"
    )

    # Dockerå·é…ç½®
    docker_volume_config: Optional[DockerVolumeConfig] = None

    # æ•°æ®é›†å‡†å¤‡
    prepared_datasets: List[PreparedDataset] = Field(
        default_factory=list,
        description="å·²å‡†å¤‡çš„æ•°æ®é›†"
    )

class PreparedDataset(BaseModel):
    """å·²å‡†å¤‡çš„æ•°æ®é›†"""

    name: str = Field(..., description="æ•°æ®é›†åç§°")
    source_path: str = Field(..., description="æºæ–‡ä»¶è·¯å¾„")
    workspace_path: str = Field(..., description="workspaceå†…è·¯å¾„")
    access_path: str = Field(..., description="ä»£ç è®¿é—®è·¯å¾„ï¼ˆç›¸å¯¹ï¼‰")
    size_mb: float = Field(..., description="å¤§å°ï¼ˆMBï¼‰")
    strategy: Literal["copy", "link"] = Field(
        default="copy",
        description="å‡†å¤‡ç­–ç•¥"
    )
```

---

## å…­ã€å®‰å…¨è®¾è®¡

### 6.1 å¤šå±‚é˜²æŠ¤

**å®‰å…¨å±‚æ¬¡**ï¼š
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              åº”ç”¨å±‚é˜²æŠ¤                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     ä»£ç æ‰«æå±‚              â”‚    â”‚
â”‚  â”‚  - ASTé™æ€åˆ†æ                 â”‚    â”‚
â”‚  â”‚  - å±é™©æ¨¡å¼åŒ¹é…               â”‚    â”‚
â”‚  â”‚  - é£é™©è¯„åˆ†ï¼ˆ0-1ï¼‰             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚            â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     ç­–ç•¥å¼•æ“å±‚                â”‚    â”‚
â”‚  â”‚  - éš”ç¦»çº§åˆ«è·¯ç”±               â”‚    â”‚
â”‚  â”‚  - èµ„æºé™åˆ¶è®¡ç®—               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚            â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     åç«¯éš”ç¦»å±‚                â”‚    â”‚
â”‚  â”‚  - Linux namespaces               â”‚    â”‚
â”‚  â”‚  - cgroupsèµ„æºé™åˆ¶              â”‚    â”‚
â”‚  â”‚  - seccompè¿‡æ»¤å™¨                â”‚    â”‚
â”‚  â”‚  - ç½‘ç»œéš”ç¦»                   â”‚    â”‚
â”‚  â”‚  - æ–‡ä»¶ç³»ç»Ÿéš”ç¦»               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚            â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     åŸºç¡€è®¾æ–½å±‚               â”‚    â”‚
â”‚  â”‚  - ä¸»æœºèµ„æºç®¡ç†               â”‚    â”‚
â”‚  â”‚  - é•œåƒæ‰«æ                   â”‚    â”‚
â”‚  â”‚  - å®¹å™¨é€ƒé€¸æ£€æµ‹               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 ä»£ç æ‰«æè§„åˆ™

**å±é™©æ¨¡å¼åº“**ï¼š
```python
DANGEROUS_PATTERNS = {
    # æ–‡ä»¶æ“ä½œ
    "file_write": r"\b(os\.remove|os\.rmdir|shutil\.rmtree)\s*\(",

    # ç½‘ç»œæ“ä½œ
    "network": r"\b(socket\.|urllib\.|requests\.|http\.client)\s*\(",

    # å­è¿›ç¨‹
    "subprocess": r"\b(subprocess\.|Popen)\s*\(",

    # åŠ¨æ€æ‰§è¡Œ
    "dynamic_exec": r"\b(exec|eval|compile|__import__)\s*\(",

    # ç³»ç»Ÿæ“ä½œ
    "system": r"\b(os\.system|sys\.exit)\s*\(",
}

RISK_WEIGHTS = {
    "file_write": 0.8,      # é«˜å±
    "network": 0.7,          # ä¸­é«˜
    "subprocess": 0.6,       # ä¸­
    "dynamic_exec": 0.9,    # é«˜
    "system": 0.95,          # æé«˜
}
```

**æ‰«æå™¨å®ç°**ï¼š
```python
class CodeScanner:
    """ä»£ç é™æ€åˆ†æå™¨"""

    def scan(self, code: str) -> CodeScanResult:
        """
        æ‰«ææµç¨‹ï¼š
        1. ASTè§£æä»£ç 
        2. æ¨¡å¼åŒ¹é…æ£€æµ‹
        3. é£é™©è¯„åˆ†è®¡ç®—
        4. ç”Ÿæˆæ‰«ææŠ¥å‘Š
        """

        tree = ast.parse(code)
        issues = []

        for node in ast.walk(tree):
            # æ£€æµ‹å¯¼å…¥
            if isinstance(node, ast.Import):
                module = node.module if isinstance(node, ast.ImportFrom) else node.names[0]
                if module in DANGEROUS_MODULES:
                    issues.append({
                        "type": "dangerous_import",
                        "module": module,
                        "line": node.lineno,
                        "severity": "high"
                    })

            # æ£€æµ‹å‡½æ•°è°ƒç”¨
            if isinstance(node, ast.Call):
                func_name = self._get_full_name(node.func)
                for pattern, weight in DANGEROUS_PATTERNS.items():
                    if re.search(pattern, func_name):
                        issues.append({
                            "type": "dangerous_call",
                            "function": func_name,
                            "line": node.lineno,
                            "severity": "high",
                            "weight": weight
                        })

        risk_score = self._calculate_risk_score(issues)

        return CodeScanResult(
            is_safe=risk_score < 0.3,
            risk_score=risk_score,
            issues=issues,
            recommended_isolation=self._get_isolation(risk_score)
        )

    def _calculate_risk_score(self, issues: List) -> float:
        """è®¡ç®—0-1ä¹‹é—´çš„é£é™©åˆ†æ•°"""
        if not issues:
            return 0.0

        total_weight = sum(
            issue.get("weight", 0.5)
            for issue in issues
        )

        # å½’ä¸€åŒ–åˆ°[0, 1]
        return min(total_weight / 3.0, 1.0)

class CodeScanResult(BaseModel):
    """ä»£ç æ‰«æç»“æœ"""

    is_safe: bool = Field(..., description="æ˜¯å¦å®‰å…¨")
    risk_score: float = Field(..., ge=0, le=1, description="é£é™©åˆ†æ•°ï¼ˆ0-1ï¼‰")
    issues: List[CodeIssue] = Field(
        default_factory=list,
        description="å‘ç°çš„å®‰å…¨é—®é¢˜"
    )
    recommended_isolation: str = Field(
        ...,
        description="å»ºè®®çš„éš”ç¦»çº§åˆ«"
    )

class CodeIssue(BaseModel):
    """ä»£ç é—®é¢˜"""
    type: str = Field(..., description="é—®é¢˜ç±»å‹")
    line: int = Field(..., ge=1, description="è¡Œå·")
    severity: str = Field(..., description="ä¸¥é‡ç¨‹åº¦ï¼šlow/medium/high/critical")
    weight: float = Field(default=0.5, description="é£é™©æƒé‡")
    function: Optional[str] = Field(None, description="ç›¸å…³å‡½æ•°")
    module: Optional[str] = Field(None, description="ç›¸å…³æ¨¡å—")
```

### 6.3 èµ„æºé™åˆ¶

**cgroupsé…ç½®**ï¼š
```python
class ResourceLimiter:
    """èµ„æºé™åˆ¶å™¨"""

    @staticmethod
    def create_cgroup_config(
        memory_mb: int,
        cpu_cores: float,
        timeout_sec: int
    ) -> str:
        """ç”Ÿæˆcgroupé…ç½®"""

        return f"""
# Memory limit: {memory_mb}M
memory.limit_in_bytes={memory_mb * 1024 * 1024 * 1024}

# CPU limit
cpu.cfs_quota_us={cpu_cores * 100000}
cpu.cfs_period_us=100000

# Time limit (cpu time)
cpu.max={timeout_sec}
"""

    @staticmethod
    def create_docker_limits(
        memory_mb: int,
        cpu_cores: float
    ) -> Dict:
        """Dockerèµ„æºé™åˆ¶é…ç½®"""

        return {
            "mem_limit": f"{memory_mb}m",
            "cpu_quota": f"{cpu_cores * 1e6}",
            "cpu_period": 100000,
            "pids_limit": 100,  # é™åˆ¶è¿›ç¨‹æ•°
        }
```

---

## ä¸ƒã€APIè®¾è®¡

### 7.1 REST APIï¼ˆv1ï¼‰

**æ ¸å¿ƒç«¯ç‚¹**ï¼š
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(
    title="ds-sandbox API",
    version="1.0.0",
    description="General-purpose AI code execution sandbox"
)

# ========== Workspaceç®¡ç† ==========

@app.post("/v1/workspaces", response_model=Workspace, status_code=201)
async def create_workspace(request: CreateWorkspaceRequest):
    """åˆ›å»ºæ–°workspace"""
    workspace = await workspace_manager.create(
        workspace_id=request.workspace_id,
        setup_dirs=request.setup_dirs
    )
    return workspace

@app.get("/v1/workspaces/{workspace_id}", response_model=Workspace)
async def get_workspace(workspace_id: str):
    """è·å–workspaceä¿¡æ¯"""
    return await workspace_manager.get(workspace_id)

@app.delete("/v1/workspaces/{workspace_id}", status_code=204)
async def delete_workspace(workspace_id: str):
    """åˆ é™¤workspaceåŠå…¶æ•°æ®"""
    await workspace_manager.delete(workspace_id)

# ========== æ•°æ®é›†ç®¡ç† ==========

@app.post("/v1/workspaces/{workspace_id}/datasets", status_code=200)
async def prepare_datasets(
    workspace_id: str,
    request: PrepareDatasetsRequest
):
    """å‡†å¤‡æ•°æ®é›†åˆ°workspace/data/"""
    await workspace_manager.prepare_datasets(
        workspace_id=workspace_id,
        datasets=request.datasets
    )
    return {"status": "prepared"}

@app.get("/v1/workspaces/{workspace_id}/datasets", response_model=List[DatasetInfo])
async def list_available_datasets():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†"""
    return await dataset_registry.list_all()

# ========== ä»£ç æ‰§è¡Œï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰==========

@app.post("/v1/workspaces/{workspace_id}/run",
         response_model=ExecutionInfo,
         status_code=201)
async def execute_code(
    workspace_id: str,
    request: ExecutionRequest
):
    """
    ç»Ÿä¸€æ‰§è¡Œå…¥å£ï¼ˆæ¨èä½¿ç”¨ï¼‰

    æµç¨‹ï¼š
    1. éªŒè¯workspaceå­˜åœ¨
    2. æ‰«æä»£ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    3. å†³å®šéš”ç¦»çº§åˆ«
    4. å‡†å¤‡æ•°æ®é›†
    5. æŒ‚è½½workspace
    6. æ‰§è¡Œä»£ç 
    7. è¿”å›ExecutionInfoï¼ˆåŒ…å«execution_idï¼‰
    """

    execution = await sandbox_manager.execute(
        code=request.code,
        workspace_id=workspace_id,
        datasets=request.datasets,
        mode=request.mode,
        timeout_sec=request.timeout_sec,
        env_vars=request.env_vars
    )

    return ExecutionInfo(
        execution_id=execution.execution_id,
        workspace_id=workspace_id,
        status="running"
    )

@app.get("/v1/workspaces/{workspace_id}/runs/{execution_id}",
         response_model=ExecutionStatus)
async def get_execution_status(
    workspace_id: str,
    execution_id: str
):
    """æŸ¥è¯¢æ‰§è¡ŒçŠ¶æ€"""
    return await execution_tracker.get_status(execution_id)

@app.post("/v1/workspaces/{workspace_id}/runs/{execution_id}/stop",
         status_code=200)
async def stop_execution(
    workspace_id: str,
    execution_id: str
):
    """åœæ­¢æ‰§è¡Œä¸­çš„ä»»åŠ¡"""
    await execution_tracker.stop(execution_id)
    return {"status": "stopped"}

@app.get("/v1/workspaces/{workspace_id}/runs/{execution_id}/logs",
          response_model=ExecutionLogs)
async def get_execution_logs(
    workspace_id: str,
    execution_id: str,
    offset: int = 0,
    limit: int = 1000
):
    """è·å–æ‰§è¡Œæ—¥å¿—ï¼ˆæµå¼ï¼‰"""
    return await execution_tracker.get_logs(
        execution_id,
        offset,
        limit
    )

# ========== ç³»ç»Ÿç®¡ç† ==========

@app.get("/v1/health", response_model=HealthStatus)
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    backends = await backend_registry.health_check()
    return HealthStatus(
        status="healthy" if all(b.status == "ready" for b in backends) else "degraded",
        backends=backends,
        version="1.0.0"
    )

@app.get("/v1/metrics", response_model=SystemMetrics)
async def get_metrics():
    """ç³»ç»ŸæŒ‡æ ‡"""
    return await metrics_collector.get_current_metrics()

# ========== é”™è¯¯å¤„ç† ==========

class SandboxErrorResponse(BaseModel):
    """ç»Ÿä¸€é”™è¯¯å“åº”"""

    error_code: str = Field(..., description="é”™è¯¯ä»£ç ï¼ˆSBX-XXXï¼‰")
    message: str = Field(..., description="ç”¨æˆ·å‹å¥½çš„é”™è¯¯æè¿°")
    details: Dict[str, Any] = Field(
        default_factory=dict,
        description="é¢å¤–é”™è¯¯è¯¦æƒ…"
    )
    request_id: str = Field(..., description="è¯·æ±‚è¿½è¸ªID")
    timestamp: str = Field(..., description="é”™è¯¯æ—¶é—´ï¼ˆISO 8601ï¼‰")

# é”™è¯¯ç å®šä¹‰
class ErrorCode:
    """æ ‡å‡†é”™è¯¯ç """
    WSP_NOT_FOUND = "SBX_WSP_001"          # Workspaceä¸å­˜åœ¨
    WSP_INVALID = "SBX_WSP_002"             # WorkspaceçŠ¶æ€æ— æ•ˆ
    DAT_NOT_FOUND = "SBX_DAT_001"           # æ•°æ®é›†ä¸å­˜åœ¨
    DAT_NOT_PREPARED = "SBX_DAT_002"        # æ•°æ®é›†æœªå‡†å¤‡
    EXEC_TIMEOUT = "SBX_EXEC_001"           # æ‰§è¡Œè¶…æ—¶
    EXEC_FAILED = "SBX_EXEC_002"             # æ‰§è¡Œå¤±è´¥
    RESOURCE_LIMIT = "SBX_RES_001"          # èµ„æºé™åˆ¶
    SEC_SCAN_FAILED = "SBX_SEC_001"         # å®‰å…¨æ‰«æå¤±è´¥
    BACKEND_UNAVAILABLE = "SBX_BAK_001"    # åç«¯ä¸å¯ç”¨

@app.exception_handler(SandboxError)
async def sandbox_error_handler(request: Request, exc: SandboxError):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    error_mapping = {
        WorkspaceNotFoundError: 404,
        DatasetNotFoundError: 400,
        DatasetNotPreparedError: 400,
        ExecutionTimeoutError: 408,
        ResourceLimitError: 413,
    }

    status_code = error_mapping.get(type(exc), 500)

    return JSONResponse(
        status_code=status_code,
        content=SandboxErrorResponse(
            error_code=exc.error_code,
            message=str(exc),
            details=exc.details if hasattr(exc, 'details') else {},
            request_id=generate_request_id()
        ).model_dump()
    )
```

### 7.2 APIç‰ˆæœ¬æ§åˆ¶

**ç‰ˆæœ¬ç­–ç•¥**ï¼š
```
URLæ ¼å¼ï¼š/v1/{resource}
å“åº”å¤´ï¼šX-API-Version: 1.0.0

ç ´åæ€§å˜æ›´ï¼šä¸»ç‰ˆæœ¬å·é€’å¢
å‘åå…¼å®¹ï¼šå°ç‰ˆæœ¬é€’å¢
Betaæ ‡è®°ï¼šv1.0.0-beta.1
```

---

## å…«ã€SDKè®¾è®¡

### 8.1 Python SDK

**æ ¸å¿ƒç±»**ï¼š
```python
from typing import Optional, List
import aiohttp

class SandboxSDK:
    """ds-sandbox Python SDK"""

    def __init__(
        self,
        api_endpoint: str = "http://localhost:8000",
        api_key: Optional[str] = None,
        timeout: int = 30
    ):
        self.endpoint = api_endpoint
        self.session = aiohttp.ClientSession()
        self.api_key = api_key

    # ========== Workspaceç®¡ç† ==========

    async def create_workspace(
        self,
        workspace_id: str,
        setup_dirs: List[str] = ["data", "models"]
    ) -> Workspace:
        """åˆ›å»ºworkspace"""
        async with self.session.post(
            f"{self.endpoint}/v1/workspaces",
            json={"workspace_id": workspace_id, "setup_dirs": setup_dirs},
            headers=self._headers()
        ) as resp:
            data = await resp.json()
            return Workspace(**data)

    async def prepare_datasets(
        self,
        workspace_id: str,
        datasets: List[str]
    ) -> None:
        """å‡†å¤‡æ•°æ®é›†"""
        async with self.session.post(
            f"{self.endpoint}/v1/workspaces/{workspace_id}/datasets",
            json={"datasets": datasets},
            headers=self._headers()
        ) as resp:
            if resp.status != 200:
                raise SandboxError.from_response(resp)

    # ========== ä»£ç æ‰§è¡Œï¼ˆä¸»è¦åŠŸèƒ½ï¼‰==========

    async def execute(
        self,
        workspace_id: str,
        code: str,
        mode: str = "safe",
        timeout_sec: int = 3600,
        datasets: List[str] = None,
        env_vars: dict = None
    ) -> ExecutionResult:
        """
        æ‰§è¡Œä»£ç ï¼ˆåŒæ­¥æˆ–å¼‚æ­¥ï¼‰

        Args:
            workspace_id: Workspace ID
            code: Pythonä»£ç 
            mode: safe/fast/secure
            timeout_sec: è¶…æ—¶æ—¶é—´
            datasets: æ•°æ®é›†åˆ—è¡¨
            env_vars: ç¯å¢ƒå˜é‡

        Returns:
            ExecutionResultå¯¹è±¡
        """

        request_data = {
            "code": code,
            "mode": mode,
            "timeout_sec": timeout_sec,
            "datasets": datasets or [],
            "env_vars": env_vars or {}
        }

        async with self.session.post(
            f"{self.endpoint}/v1/workspaces/{workspace_id}/run",
            json=request_data,
            headers=self._headers()
        ) as resp:
            if resp.status != 201:
                raise SandboxError.from_response(resp)

            data = await resp.json()
            execution_id = data["execution_id"]

            # ç­‰å¾…æ‰§è¡Œå®Œæˆï¼ˆè½®è¯¢æˆ–ä¸€æ¬¡æ€§ç­‰å¾…ï¼‰
            result = await self._wait_for_completion(
                execution_id,
                timeout_sec=timeout_sec
            )

            return result

    async def get_execution_status(
        self,
        workspace_id: str,
        execution_id: str
    ) -> ExecutionStatus:
        """æŸ¥è¯¢æ‰§è¡ŒçŠ¶æ€"""
        async with self.session.get(
            f"{self.endpoint}/v1/workspaces/{workspace_id}/runs/{execution_id}",
            headers=self._headers()
        ) as resp:
            if resp.status != 200:
                raise SandboxError.from_response(resp)
            return ExecutionStatus(**await resp.json())

    async def stop_execution(
        self,
        workspace_id: str,
        execution_id: str
    ) -> None:
        """åœæ­¢æ‰§è¡Œ"""
        async with self.session.post(
            f"{self.endpoint}/v1/workspaces/{workspace_id}/runs/{execution_id}/stop",
            headers=self._headers()
        ) as resp:
            if resp.status != 200:
                raise SandboxError.from_response(resp)

    # ========== è¾…åŠ©æ–¹æ³• ==========

    async def list_workspaces(self) -> List[Workspace]:
        """åˆ—å‡ºæ‰€æœ‰workspace"""
        async with self.session.get(
            f"{self.endpoint}/v1/workspaces",
            headers=self._headers()
        ) as resp:
            return Workspace(**(await resp.json())

    async def delete_workspace(self, workspace_id: str) -> None:
        """åˆ é™¤workspace"""
        async with self.session.delete(
            f"{self.endpoint}/v1/workspaces/{workspace_id}",
            headers=self._headers()
        ) as resp:
            if resp.status != 204:
                raise SandboxError.from_response(resp)

    def _headers(self) -> dict:
        """ç”Ÿæˆè¯·æ±‚å¤´"""
        headers = {
            "Content-Type": "application/json",
            "X-API-Version": "1.0.0"
        }
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"
        return headers

    async def _wait_for_completion(
        self,
        execution_id: str,
        timeout_sec: int
    ) -> ExecutionResult:
        """ç­‰å¾…æ‰§è¡Œå®Œæˆ"""
        start_time = time.time()

        while time.time() - start_time < timeout_sec:
            status = await self.get_execution_status(
                execution_id.split('-')[0],  # å»æ‰å‰ç¼€
                execution_id
            )

            if status.status in ["completed", "failed"]:
                result = await self.get_execution_result(execution_id)
                return result

            await asyncio.sleep(0.5)  # è½®è¯¢é—´éš”

        raise ExecutionTimeoutError(f"Execution {execution_id} timeout")

class ExecutionStatus(BaseModel):
    """æ‰§è¡ŒçŠ¶æ€"""
    execution_id: str
    workspace_id: str
    status: Literal["queued", "running", "completed", "failed", "stopped"]
    created_at: str
    started_at: Optional[str]
    completed_at: Optional[str]
    result: Optional[ExecutionResult] = None
```

### 8.2 ä½¿ç”¨ç¤ºä¾‹

```python
# examples/basic_usage.py

import asyncio
from ds_sandbox import SandboxSDK

async def main():
    # åˆå§‹åŒ–SDK
    sdk = SandboxSDK(
        api_endpoint="http://localhost:8000"
    )

    try:
        # 1. åˆ›å»ºworkspace
        workspace = await sdk.create_workspace(
            workspace_id="demo-exp-001",
            setup_dirs=["data", "models", "outputs"]
        )
        print(f"âœ“ Workspace created: {workspace.workspace_id}")

        # 2. å‡†å¤‡æ•°æ®é›†
        await sdk.prepare_datasets(
            workspace_id="demo-exp-001",
            datasets=["bike-sharing-demand", "titanic"]
        )
        print("âœ“ Datasets prepared")

        # 3. æ‰§è¡Œä»£ç 
        result = await sdk.execute(
            workspace_id="demo-exp-001",
            code="""
import pandas as pd
import os

# æŸ¥çœ‹workspaceç»“æ„
print(f"Working directory: {os.getcwd()}")
print(f"Contents: {os.listdir('.')}")

# è¯»å–æ•°æ®ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
df_bike = pd.read_csv('data/bike-sharing-demand/train.csv')
print(f"Bike dataset: {df_bike.shape}")

df_titanic = pd.read_csv('data/titanic/train.csv')
print(f"Titanic dataset: {df_titanic.shape}")

# ç®€å•åˆ†æ
print(f"\\n=== Basic Statistics ===")
print(f"Bike rows: {len(df_bike)}, columns: {list(df_bike.columns)}")
print(f"Titanic rows: {len(df_titanic)}, columns: {list(df_titanic.columns)}")

# ä¿å­˜æ¨¡å‹åˆ°models/ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
from sklearn.ensemble import RandomForestClassifier
from joblib import dump

model = RandomForestClassifier(n_estimators=10, max_depth=5)
X = df_bike[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp_1', 'atemp_2', 'atemp_3', 'atemp_4', 'humidity', 'windspeed']]
y = df_bike['count'] > df_bike['count'].median()
model.fit(X, y)

model_path = 'models/rf_bike.pkl'
dump(model, model_path)
print(f"\\nModel saved to: {model_path}")

# éªŒè¯
import os
print(f"\\nFiles in models/: {os.listdir('models/')}")
""",
            mode="fast",
            timeout_sec=600
        )

        # 4. æ£€æŸ¥ç»“æœ
        if result.success:
            print("âœ“ Execution succeeded")
            print(f"  Output: {result.stdout[:200]}...")
            if result.artifacts:
                print(f"  Artifacts: {result.artifacts}")
            print(f"  Duration: {result.duration_ms}ms")
        else:
            print(f"âœ— Execution failed")
            print(f"  Error: {result.stderr}")

    except Exception as e:
        print(f"âœ— Error: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ä¹ã€æ•°æ®ç®¡ç†

### 9.1 Workspaceæ•°æ®æµ

```
ä¸­å¤®æ•°æ®ä»“åº“              Workspaceï¼ˆæ‰§è¡Œæ—¶ï¼‰
/opt/datasets/          /opt/workspaces/{id}/
  â”œâ”€â”€ bike-sharing/         â””â”€â”€ data/
  â”œâ”€â”€ titanic/               â””â”€â”€ models/
  â””â”€â”€ housing/             â””â”€â”€ outputs/

å‡†å¤‡é˜¶æ®µï¼ˆexecuteå‰ï¼‰ï¼š
1. validate datasets
2. copy/link to /opt/workspaces/{id}/data/
3. verify integrity
4. record metadata

æ‰§è¡Œé˜¶æ®µï¼š
1. mount /opt/workspaces/{id} â†’ /workspace
2. codeè¿è¡Œåœ¨ /workspace
3. è®¿é—® data/{dataset}/file.csv
4. ä¿å­˜åˆ° models/{name}.pkl
```

### 9.2 æ•°æ®é›†æ³¨å†Œ

```python
class DatasetRegistry:
    """æ•°æ®é›†æ³¨å†Œè¡¨"""

    def __init__(self, registry_path: str = "/opt/datasets"):
        self.registry_path = Path(registry_path)
        self._index_file = self.registry_path / ".index.json"

    async def register(
        self,
        name: str,
        source_path: str,
        format: str,
        description: str = None,
        tags: List[str] = None
    ) -> DatasetInfo:
        """
        æ³¨å†Œæ–°æ•°æ®é›†

        æµç¨‹ï¼š
        1. éªŒè¯source_pathå­˜åœ¨
        2. è®¡ç®—sizeå’Œchecksum
        3. æ›´æ–°ç´¢å¼•æ–‡ä»¶
        4. å¯é€‰ï¼šåˆ›å»ºç¬¦å·é“¾æ¥åŠ é€Ÿ
        """

        # è¯»å–ç°æœ‰ç´¢å¼•
        index = self._load_index()

        # æ£€æŸ¥é‡å¤
        if name in index:
            raise DatasetAlreadyExistsError(name)

        # æ”¶é›†å…ƒæ•°æ®
        metadata = {
            "size_mb": self._calculate_size(source_path),
            "format": format,
            "checksum": self._checksum(source_path),
            "registered_at": datetime.utcnow().isoformat(),
            "description": description,
            "tags": tags or []
        }

        # æ›´æ–°ç´¢å¼•
        index[name] = {
            "source_path": str(source_path),
            "metadata": metadata
        }

        self._save_index(index)

        return DatasetInfo(
            name=name,
            source_path=source_path,
            **metadata
        )

    async def get(self, name: str) -> DatasetInfo:
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        index = self._load_index()
        if name not in index:
            raise DatasetNotFoundError(name)
        return DatasetInfo(
            name=name,
            **index[name]
        )

    def _load_index(self) -> dict:
        """åŠ è½½ç´¢å¼•æ–‡ä»¶"""
        if self._index_file.exists():
            with open(self._index_file, 'r') as f:
                return json.load(f)
        return {}

    def _save_index(self, index: dict):
        """ä¿å­˜ç´¢å¼•æ–‡ä»¶"""
        self._index_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self._index_file, 'w') as f:
            json.dump(index, f, indent=2)
```

---

## åã€æµ‹è¯•ç­–ç•¥

### 10.1 æµ‹è¯•é‡‘å­—å¡”

```
                /\
               /  \
              /    \ E2E Tests
             /      \______å•å…ƒæµ‹è¯•ï¼ˆæ ¸å¿ƒæ¨¡å—ï¼‰
            /               \     /  \
            /               \     \    \é›†æˆæµ‹è¯•ï¼ˆçœŸå®ç¯å¢ƒï¼‰
           /               \     /    \
          /                \     /______æ€§èƒ½ä¸å‹åŠ›æµ‹è¯•
         /                \    /
        /__________________________\
```

### 10.2 å•å…ƒæµ‹è¯•è¦†ç›–

```python
# tests/test_manager.py

import pytest
from ds_sandbox import SandboxManager
from ds_sandbox.types import SandboxConfig

@pytest.fixture
async def sandbox_manager():
    """æµ‹è¯•ç”¨SandboxManagerå®ä¾‹"""
    config = SandboxConfig(
        default_backend="docker",  # æµ‹è¯•ç”¨Dockeråç«¯
        workspace_base_dir="/tmp/test_workspaces"
    )
    return SandboxManager(config=config)

@pytest.mark.asyncio
async def test_create_workspace(sandbox_manager):
    """æµ‹è¯•workspaceåˆ›å»º"""
    workspace = await sandbox_manager.create_workspace("test-ws-001")

    assert workspace.workspace_id == "test-ws-001"
    assert workspace.host_path.exists()
    assert "data" in workspace.subdirs
    assert "models" in workspace.subdirs
    assert "outputs" in workspace.subdirs

@pytest.mark.asyncio
async def test_prepare_datasets(sandbox_manager):
    """æµ‹è¯•æ•°æ®é›†å‡†å¤‡"""
    await sandbox_manager.create_workspace("test-ws-002")

    await sandbox_manager.prepare_datasets(
        workspace_id="test-ws-002",
        datasets=["test-dataset-1", "test-dataset-2"]
    )

    workspace = await sandbox_manager.get("test-ws-002")
    data_dir = workspace.host_path / "data"

    assert (data_dir / "test-dataset-1").exists()
    assert (data_dir / "test-dataset-2").exists()

@pytest.mark.asyncio
async def test_code_execution(sandbox_manager):
    """æµ‹è¯•ä»£ç æ‰§è¡Œ"""
    await sandbox_manager.create_workspace("test-ws-003")

    result = await sandbox_manager.execute(
        workspace_id="test-ws-003",
        code="print('Hello, sandbox!')",
        mode="fast"
    )

    assert result.success is True
    assert "Hello, sandbox!" in result.stdout
    assert result.execution_id is not None

@pytest.mark.asyncio
async def test_resource_limits(sandbox_manager):
    """æµ‹è¯•èµ„æºé™åˆ¶"""
    await sandbox_manager.create_workspace("test-ws-004")

    with pytest.raises(TimeoutError):
        await sandbox_manager.execute(
            workspace_id="test-ws-004",
            code="import time; time.sleep(10)",
            timeout_sec=2  # 2ç§’è¶…æ—¶
        )

@pytest.mark.asyncio
async def test_code_scanning(sandbox_manager):
    """æµ‹è¯•ä»£ç æ‰«æ"""
    from ds_sandbox.security import CodeScanner

    scanner = CodeScanner()

    # å®‰å…¨ä»£ç 
    safe_result = scanner.scan("import pandas as pd\ndf = pd.DataFrame()")
    assert safe_result.is_safe is True
    assert safe_result.risk_score < 0.1

    # å±é™©ä»£ç 
    dangerous_result = scanner.scan("import os; os.system('rm -rf /')")
    assert dangerous_result.is_safe is False
    assert dangerous_result.risk_score > 0.7
```

### 10.3 é›†æˆæµ‹è¯•

```python
# tests/integration/test_docker_backend.py

import pytest
import asyncio
from ds_sandbox.backends.docker import DockerSandbox

@pytest.mark.integration
@pytest.mark.asyncio
async def test_docker_execution():
    """æµ‹è¯•Dockeråç«¯å®é™…æ‰§è¡Œ"""
    backend = DockerSandbox()

    workspace = DockerSandbox.create_test_workspace("integration-test")

    result = await backend.execute(
        workspace=workspace,
        code="""
import pandas as pd
df = pd.read_csv('data/test.csv')
print(df.head())
""",
        timeout_sec=30
    )

    assert result.success
    assert "test.csv" in result.stdout

@pytest.mark.integration
@pytest.mark.asyncio
async def test_docker_isolation():
    """æµ‹è¯•Dockeréš”ç¦»æ€§"""
    backend = DockerSandbox()

    # å°è¯•è®¿é—®å®¿ä¸»æœºæ–‡ä»¶ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
    result = await backend.execute(
        workspace=backend.create_test_workspace("isolation-test"),
        code="""
# å°è¯•è¯»å–å®¿ä¸»æœºæ–‡ä»¶
try:
    with open('/etc/passwd', 'r') as f:
        print(f'Content: {f.read()[:100]}')
except Exception as e:
    print(f'Failed: {e}')
"""
    )

    # åº”è¯¥å¤±è´¥
    assert result.success is False
    assert "Permission denied" in result.stderr or "Operation not permitted" in result.stderr
```

---

## åä¸€ã€é‡Œç¨‹ç¢‘

### Phase 0: é¡¹ç›®ï¿½ï¼ˆ1å‘¨ï¼‰

**ç›®æ ‡**ï¼š
- âœ… é¡¹ç›®ç»“æ„æ­å»º
- âœ… é…ç½®æ–‡ä»¶å°±ç»ª
- âœ… åŸºç¡€æµ‹è¯•æ¡†æ¶

**äº¤ä»˜ç‰©**ï¼š
```
ds-sandbox/
â”œâ”€â”€ pyproject.toml        âœ“
â”œâ”€â”€ README.md              âœ“
â”œâ”€â”€ LICENSE                âœ“
â”œâ”€â”€ src/ds_sandbox/       âœ“
â”‚   â”œâ”€â”€ __init__.py      âœ“
â”‚   â”œâ”€â”€ types.py         âœ“
â”‚   â””â”€â”€ errors.py        âœ“
â””â”€â”€ tests/                 âœ“
    â”œâ”€â”€ conftest.py          âœ“
    â””â”€â”€ test_manager.py    âœ“
```

### Phase 1: æ ¸å¿ƒMVPï¼ˆ4-6å‘¨ï¼‰

**ç›®æ ‡**ï¼š
- âœ… Dockeråç«¯å®ç°
- âœ… Workspaceç®¡ç†å®ç°
- âœ… åŸºç¡€REST API
- âœ… æ•°æ®é›†æ³¨å†Œä¸å‡†å¤‡
- âœ… ä»£ç æ‰«æä¸ç­–ç•¥è·¯ç”±
- âœ… Python SDK
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡>80%

**éªŒæ”¶æ ‡å‡†**ï¼š
```bash
# åŠŸèƒ½éªŒè¯
âœ“ Docker backendå¯æ‰§è¡Œä»£ç 
âœ“ Workspaceå¯åˆ›å»ºå’Œå‡†å¤‡æ•°æ®
âœ“ REST API /v1/workspaces/{id}/run å¯ç”¨
âœ“ Python SDKå¯å¼‚æ­¥æ‰§è¡Œä»£ç 
âœ“ æ•°æ®é›†å¯å‡†å¤‡åˆ°workspace/data/
âœ“ ä»£ç æ‰«æå¯æ£€æµ‹å±é™©æ“ä½œ

# æ€§èƒ½åŸºå‡†
âœ“ Dockerå¯åŠ¨æ—¶é—´: <500ms (P50)
âœ“ æ‰§è¡Œåå: >100 exec/min (å•æœº)
âœ“ å†…å­˜å¼€é”€: <50MB (ç©ºè½½)
```

### Phase 2: å®‰å…¨éš”ç¦»ï¼ˆ6-8å‘¨ï¼‰

**ç›®æ ‡**ï¼š
- âœ… Firecrackeråç«¯å®ç°
- âœ… Kata Containersåç«¯å®ç°
- âœ… å®Œæ•´å®‰å…¨ç­–ç•¥ï¼ˆç½‘ç»œã€èµ„æºï¼‰
- âœ… å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
- âœ… æ€§èƒ½ç›‘æ§æŒ‡æ ‡

**éªŒæ”¶æ ‡å‡†**ï¼š
```bash
# åŠŸèƒ½éªŒè¯
âœ“ Firecracker backendå¯æ‰§è¡Œä»£ç 
âœ“ éš”ç¦»çº§åˆ«è‡ªåŠ¨è·¯ç”±å·¥ä½œ
âœ“ ç½‘ç»œç­–ç•¥ï¼ˆdisabled/whitelistï¼‰ç”Ÿæ•ˆ
âœ“ èµ„æºé™åˆ¶ï¼ˆå†…å­˜/CPUï¼‰ç”Ÿæ•ˆ
âœ“ å®¡è®¡æ—¥å¿—è®°å½•æ¯æ¬¡æ‰§è¡Œ

# å®‰å…¨éªŒè¯
âœ“ å®¹å™¨é€ƒé€¸é˜²æŠ¤
âœ“ æ–‡ä»¶ç³»ç»Ÿéš”ç¦»ï¼ˆç‹¬ç«‹rootfsï¼‰
âœ“ ç½‘ç»œéš”ç¦»ï¼ˆç‹¬ç«‹netnsï¼‰
âœ“ è¿›ç¨‹éš”ç¦»ï¼ˆç‹¬ç«‹pidnsï¼‰
```

### Phase 3: K8sé›†æˆï¼ˆ4-6å‘¨ï¼‰

**ç›®æ ‡**ï¼š
- âœ… K8s CRDå®šä¹‰
- âœ… Helm Charts
- âœ… Operatorå®ç°ï¼ˆkopfï¼‰
- âœ… æŒä¹…åŒ–å­˜å‚¨ï¼ˆPVCï¼‰

**éªŒæ”¶æ ‡å‡†**ï¼š
```bash
# åŠŸèƒ½éªŒè¯
âœ“ K8s Sandbox CRDå¯åˆ›å»º
âœ“ Helmå®‰è£…å¯éƒ¨ç½²sandbox
âœ“ Operatorè‡ªåŠ¨ç®¡ç†sandboxç”Ÿå‘½å‘¨æœŸ
âœ“ PVCæŒä¹…åŒ–å·¥ä½œæ­£å¸¸
âœ“ å¤šç§Ÿæˆ·éš”ç¦»æœ‰æ•ˆ

# K8séªŒè¯
kubectl get sandbox -n test-001  âœ“
kubectl describe workspace test-001     âœ“
kubectl logs -f sandbox/test-001      âœ“
```

---

## åäºŒã€æŠ€æœ¯é€‰å‹

### 12.1 æ ¸å¿ƒä¾èµ–

```toml
[project.dependencies]
# æ ¸å¿ƒæ¡†æ¶
fastapi = "^0.100.0"          # Webæ¡†æ¶
pydantic = "^2.0"               # æ•°æ®éªŒè¯
pydantic-settings = "^2.0"       # é…ç½®ç®¡ç†
aiofiles = "^23.0"              # å¼‚æ­¥æ–‡ä»¶æ“ä½œ

# Jupyter/ç¬”è®°æœ¬æ‰§è¡Œ
nbclient = "^0.10.0"             # Notebookæ‰§è¡Œå¼•æ“
nbformat = "^5.0.0"              # Notebookæ ¼å¼

# Dockeré›†æˆ
docker = "^7.0.0"                # Docker SDK

# å¼€å‘å·¥å…·ï¼ˆå¼€å‘ä¾èµ–ï¼‰
pytest = "^7.0.0"                # æµ‹è¯•æ¡†æ¶
pytest-asyncio = "^0.21.0"      # å¼‚æ­¥æµ‹è¯•
pytest-cov = "^4.0.0"             # è¦†ç›–ç‡
ruff = "^0.1.0"                   # ä»£ç æ ¼å¼åŒ–
mypy = "^1.0.0"                   # ç±»å‹æ£€æŸ¥
black = "^23.0.0"                  # ä»£ç æ ¼å¼åŒ–ï¼ˆå¯é€‰ï¼‰

# æ–‡æ¡£å·¥å…·
mkdocs = "^1.5.0"                 # æ–‡æ¡£ç”Ÿæˆ
mkdocs-material = "^9.0.0"         # ä¸»é¢˜

# å¯é€‰ä¾èµ–ï¼ˆæŒ‰åç«¯ï¼‰
firecracker-go = {version = ">=1.0.0", optional = true}  # Firecracker
```

### 12.2 Dockeré…ç½®

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY pyproject.toml ./
RUN pip install --no-cache-dir -e .

# å®‰è£…ds-sandbox
RUN pip install .

# é»˜è®¤é…ç½®
ENV SANDBOX_DEFAULT_BACKEND=docker
ENV SANDBOX_WORKSPACE_BASE=/opt/workspaces
ENV SANDBOX_DATASET_DIR=/opt/datasets

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s \
  CMD curl -f http://localhost:8000/v1/health || exit 1

# è¿è¡ŒAPIæœåŠ¡å™¨
CMD ["uvicorn", "ds_sandbox.api.rest:app",
     "--host", "0.0.0.0",
     "--port", "8000",
     "--log-level", "info"]
```

### 12.3 è¿è¡Œæ—¶é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  ds-sandbox-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - SANDBOX_DEFAULT_BACKEND=docker
      - SANDBOX_WORKSPACE_BASE=/opt/workspaces
      - SANDBOX_DATASET_DIR=./test_datasets
    volumes:
      - ./data:/opt/datasets
      - ./workspaces:/opt/workspaces
```

---

## é™„å½•Aï¼šå¿«é€Ÿå¼€å§‹æŒ‡å—

### 5åˆ†é’Ÿä½“éªŒds-sandbox

```bash
# 1. å®‰è£…ds-sandbox
pip install ds-sandbox

# 2. å¯åŠ¨APIæœåŠ¡å™¨ï¼ˆé»˜è®¤Dockeråç«¯ï¼‰
ds-sandbox-api &

# 3. åˆ›å»ºworkspaceå¹¶æ‰§è¡Œä»£ç 
curl -X POST http://localhost:8000/v1/workspaces \
  -H "Content-Type: application/json" \
  -d '{"workspace_id": "demo-001"}'

# 4. æ‰§è¡ŒPythonä»£ç 
curl -X POST http://localhost:8000/v1/workspaces/demo-001/run \
  -H "Content-Type: application/json" \
  -d '{
    "code": "import pandas as pd; print(pd.__version__)",
    "mode": "fast"
  }'

# é¢„æœŸå“åº”ï¼š
# {
#   "execution_id": "exec-123456",
#   "workspace_id": "demo-001",
#   "status": "running"
# }
```

---

## é™„å½•Bï¼šä¸DSLightingé›†æˆ

### DSLightingä½¿ç”¨ds-sandbox

```python
# dslighting/dslighting/sandbox/adapter.py

"""
DSLighting Sandboxé€‚é…å™¨
æ¡¥æ¥DSLightingçš„workspaceæœåŠ¡åˆ°ds-sandbox
"""

from ds_sandbox import SandboxSDK
from dslighting.services.workspace import WorkspaceService

class SandboxService:
    """DSLighting SandboxæœåŠ¡ï¼ˆé€‚é…å™¨æ¨¡å¼ï¼‰"""

    def __init__(self, workspace: WorkspaceService):
        """
        Args:
            workspace: DSLightingçš„workspaceæœåŠ¡
        """
        self.workspace = workspace

        # åˆå§‹åŒ–ds-sandbox SDK
        self.sdk = SandboxSDK(
            api_endpoint="http://localhost:8000"  # ds-sandbox API
        )

        # å°†DSLighting workspaceæ˜ å°„åˆ°ds-sandbox workspace
        self._ensure_sandbox_workspace()

    def _ensure_sandbox_workspace(self) -> None:
        """ç¡®ä¿ds-sandboxä¸­æœ‰å¯¹åº”workspace"""
        # é€šè¿‡SDKåˆ›å»ºworkspaceï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not hasattr(self, '_sandbox_workspace_created'):
            from ds_sandbox import Workspace as SandboxWorkspace

            sandbox_ws = SandboxWorkspace(
                workspace_id=self.workspace.workspace_id,
                host_path="/opt/sandbox-workspaces",  # ds-sandboxè·¯å¾„
                subdirs=["data", "models", "outputs", "code"]
            )

            # è°ƒç”¨ds-sandbox APIåˆ›å»ºworkspace
            # ï¼ˆè¿™é‡Œä¼šå®é™…åˆ›å»ºç›®å½•ç»“æ„ï¼‰
            self._sandbox_workspace_created = True

    async def run_script(
        self,
        script_code: str,
        timeout: int = 600
    ) -> ExecutionResult:
        """
        æ‰§è¡ŒPythonè„šæœ¬ï¼ˆå‘åå…¼å®¹ï¼‰

        æµç¨‹ï¼š
        1. é€šè¿‡ds-sandboxæ‰§è¡Œä»£ç 
        2. å¤„ç†ç»“æœå’Œé”™è¯¯
        """
        try:
            result = await self.sdk.execute(
                workspace_id=self.workspace.workspace_id,
                code=script_code,
                mode="safe"
            )

            # è½¬æ¢ç»“æœæ ¼å¼ä»¥åŒ¹é…DSLightingæœŸæœ›
            return ExecutionResult(
                success=result.success,
                stdout=result.stdout,
                stderr=result.stderr,
                exc_type=result.exc_type if not result.success else None,
                metadata=result.metadata
            )

        except Exception as e:
            return ExecutionResult(
                success=False,
                stderr=str(e),
                exc_type=type(e).__name__
            )

    async def notebook_executor(self, timeout: int):
        """Notebookæ‰§è¡Œå™¨ï¼ˆå‘åå…¼å®¹ï¼‰"""
        from ds_sandbox.api import NotebookExecutor as SandboxNotebookExecutor

        executor = SandboxNotebookExecutor(
            workspace_id=self.workspace.workspace_id,
            api_endpoint="http://localhost:8000"
        )

        return await executor.start()
```

**é…ç½®é›†æˆ**ï¼š
```toml
# dslighting/pyproject.toml

[project.dependencies]
# æ·»åŠ ds-sandboxä¾èµ–
ds-sandbox = "^1.0.0"  # ç‰ˆæœ¬è¦æ±‚

[project.optional-dependencies]
# å¼€å‘ä¾èµ–ä¼šè‡ªåŠ¨å®‰è£…
```

---

## é™„å½•Aï¼š5åˆ†é’Ÿå¿«é€ŸéªŒè¯

### æ­¥éª¤1ï¼šå…‹éš†å¹¶å®‰è£…ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
git clone https://github.com/usail-hkust/ds-sandbox.git
cd ds-sandbox
pip install -e .
```

### æ­¥éª¤2ï¼šåˆ›å»ºworkspaceå¹¶æ‰§è¡Œä»£ç ï¼ˆ3åˆ†é’Ÿï¼‰

```bash
# å¯åŠ¨APIæœåŠ¡å™¨ï¼ˆé»˜è®¤Dockerï¼‰
ds-sandbox-api &

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œä»£ç 
python - << 'EOF'
import asyncio
from ds_sandbox import SandboxSDK

async def main():
    sdk = SandboxSDK()

    # åˆ›å»ºworkspace
    ws = await sdk.create_workspace("quickstart", ["data", "models"])
    print(f"Workspace: {ws.host_path}")

    # æ‰§è¡Œä»£ç 
    result = await sdk.execute(
        workspace_id="quickstart",
        code="import pandas as pd; print(pd.__version__)"
    )

    print(result.stdout)
    print(f"Execution ID: {result.execution_id}")

asyncio.run(main())
EOF
```

### æ­¥éª¤3ï¼šéªŒè¯ç»“æœï¼ˆå¯é€‰ï¼Œæœ€é•¿5åˆ†é’Ÿï¼‰

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ… Workspace: /opt/workspaces/quickstart
âœ… Status: ready
âœ… Execution completed
Output: 2.0.3
```

---

## ğŸ“Š é¡¹ç›®æ–‡ä»¶æ€»è§ˆ

å·²åˆ›å»ºçš„æ ¸å¿ƒæ–‡ä»¶ï¼š
```
âœ“ README.md                                    - é¡¹ç›®è¯´æ˜
âœ“ LICENSE                                      - Apache-2.0åè®®
âœ“ PROPOSAL.md                                 - å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆ
âœ“ pyproject.toml                               - æ‰“åŒ…é…ç½®
âœ“ src/ds_sandbox/                            - æºä»£ç åŒ…
  âœ“ __init__.py
  âœ“ types.py                                  - ç±»å‹å®šä¹‰
  âœ“ errors.py                                 - å¼‚å¸¸ä½“ç³»
  âœ“ config.py                                 - é…ç½®æ¨¡å‹
  âœ“ manager.py                                - æ ¸å¿ƒç®¡ç†å™¨ï¼ˆéª¨æ¶ï¼‰
  âœ“ backends/
    âœ“ __init__.py                           - åç«¯åŸºç±»
    âœ“ docker.py                              - Dockerå®ç°ï¼ˆæ ¸å¿ƒä»£ç ï¼‰
âœ“ workspace/                                 - Workspaceç®¡ç†ï¼ˆéª¨æ¶ï¼‰
  âœ“ data/                                      - æ•°æ®ç®¡ç†ï¼ˆéª¨æ¶ï¼‰
  âœ“ storage/                                   - å­˜å‚¨æŠ½è±¡ï¼ˆéª¨æ¶ï¼‰
  âœ“ security/                                  - å®‰å…¨å±‚ï¼ˆéª¨æ¶ï¼‰
  âœ“ monitoring/                                - ç›‘æ§ï¼ˆéª¨æ¶ï¼‰
  âœ“ api/                                      - APIå±‚ï¼ˆéª¨æ¶ï¼‰
    âœ“ examples/basic_execution.py          - ä½¿ç”¨ç¤ºä¾‹
âœ“ setup.py                                     - å®‰è£…è„šæœ¬
âœ“ .gitignore                                  - Gitå¿½ç•¥è§„åˆ™
```

**ä¸‹ä¸€æ­¥**ï¼š
1. å®ç°æ ¸å¿ƒç®¡ç†å™¨ï¼ˆmanager.pyï¼‰- Phase 1ï¼ŒWeek 1-2
2. å®Œæ•´Dockeråç«¯å®ç°ï¼ˆbackends/docker.pyï¼‰- Phase 1ï¼ŒWeek 3-4
3. å®ç°åŸºç¡€APIæœåŠ¡å™¨ï¼ˆapi/rest.pyï¼‰- Phase 1ï¼ŒWeek 3-4
4. æ·»åŠ å•å…ƒæµ‹è¯• - Phase 1ï¼ŒWeek 4-6

**å°±ç»ªçŠ¶æ€**ï¼š
- âœ… é¡¹ç›®ç»“æ„å®Œæ•´
- âœ… ç±»å‹ç³»ç»Ÿå®šä¹‰æ¸…æ™°
- âœ… é”™è¯¯ä½“ç³»å°±ç»ª
- âœ… é…ç½®ç®¡ç†å®ç°
- âœ… Dockeråç«¯æ¡†æ¶å®Œæ•´

**å¯ç«‹å³éªŒè¯**ï¼š
```bash
cd /Users/liufan/projects/share/ds-sandbox
pip install -e .
python -m pytest tests/ -v  # è¿è¡ŒåŸºç¡€æµ‹è¯•ï¼ˆéª¨æ¶ä¼šé€šè¿‡ï¼‰
python examples/basic_execution.py  # è¿è¡Œç¤ºä¾‹ï¼ˆä¼šå¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰å®ç°ï¼‰
```

---

## ç»“è¯­

ds-sandboxé¡¹ç›®å®šä½ä¸º**é€šç”¨çš„AIä»£ç æ‰§è¡Œæ²™ç®±æ¡†æ¶**ï¼Œå¡«è¡¥å½“å‰å¼€æºæ–¹æ¡ˆçš„ç©ºç™½ã€‚é€šè¿‡Workspace-Firstçš„æ•°æ®ç®¡ç†ã€å¯æ’æ‹”çš„åç«¯æ¶æ„å’Œå®Œå–„çš„APIè®¾è®¡ï¼Œä¸ºAI agentæä¾›ç”Ÿäº§çº§çš„ä»£ç æ‰§è¡Œèƒ½åŠ›ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š
1. âœ… **å®Œå…¨ç‹¬ç«‹** - é›¶ä¸Šå±‚ä¾èµ–ï¼Œå¯å•ç‹¬å‘å¸ƒå’Œä½¿ç”¨
2. âœ… **WorkspaceåŸç”Ÿ** - æ•°æ®åœ¨workspaceç›¸å¯¹è·¯å¾„ï¼Œç¬¦åˆDSä¹ æƒ¯
3. âœ… **ç­–ç•¥é©±åŠ¨** - æ ¹æ®é£é™©è‡ªåŠ¨é€‰æ‹©éš”ç¦»çº§åˆ«
4. âœ… **ç”Ÿäº§å°±ç»ª** - å®¡è®¡ã€ç›‘æ§ã€é™æµé½å…¨
5. âœ… **æ˜“äºé›†æˆ** - REST/SDK/MCPä¸‰ç§æ¥å£

**é¢„æœŸå½±å“**ï¼š
- ä¸ºAI agentæä¾›å¯é çš„ä»£ç æ‰§è¡Œç¯å¢ƒ
- ç»Ÿä¸€çš„æ•°æ®ç§‘å­¦æ²™ç®±æ ‡å‡†
- é™ä½å¤šé¡¹ç›®é›†æˆæˆæœ¬

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-12
**çŠ¶æ€**: å¾…å®¡æ ¸
